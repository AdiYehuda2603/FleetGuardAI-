# -*- coding: utf-8 -*-
"""
Chart Insights Generator
××™×™×¦×¨ ×ª×•×‘× ×•×ª ××•×˜×•××˜×™×•×ª ×œ×’×¨×¤×™× ×‘×“×©×‘×•×¨×“
"""

import pandas as pd
import numpy as np
from datetime import datetime


class ChartInsightsGenerator:
    """
    ××—×œ×§×” ×œ×™×™×¦×•×¨ ×ª×•×‘× ×•×ª ××•×˜×•××˜×™×•×ª ××’×¨×¤×™×
    """

    def __init__(self):
        pass

    def analyze_workshop_costs(self, df):
        """
        × ×™×ª×•×— ×”×•×¦××•×ª ×œ×¤×™ ××•×¡×š

        Args:
            df: DataFrame ×¢× ×¢××•×“×•×ª workshop, total

        Returns:
            dict: ×ª×•×‘× ×•×ª ×¢×œ ×”×ª×¤×œ×’×•×ª ×¢×œ×•×™×•×ª ×‘×™×Ÿ ××•×¡×›×™×
        """
        if df.empty or 'workshop' not in df.columns or 'total' not in df.columns:
            return {"insights": [], "alert_level": "info"}

        cost_by_garage = df.groupby('workshop')['total'].agg(['sum', 'mean', 'count']).reset_index()
        cost_by_garage = cost_by_garage.sort_values('sum', ascending=False)

        insights = []
        alert_level = "success"

        # ××•×¡×š ×”×›×™ ×™×§×¨
        most_expensive = cost_by_garage.iloc[0]
        insights.append(
            f"ğŸ† **×”××•×¡×š ×¢× ×”×”×•×¦××” ×”×›×•×œ×œ×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨:** {most_expensive['workshop']} "
            f"(â‚ª{most_expensive['sum']:,.0f}, {most_expensive['count']:.0f} ×˜×™×¤×•×œ×™×)"
        )

        # ××•×¡×š ×”×›×™ ×–×•×œ
        cheapest = cost_by_garage.iloc[-1]
        insights.append(
            f"ğŸ’° **×”××•×¡×š ×”×›×œ×›×œ×™ ×‘×™×•×ª×¨:** {cheapest['workshop']} "
            f"(â‚ª{cheapest['sum']:,.0f}, {cheapest['count']:.0f} ×˜×™×¤×•×œ×™×)"
        )

        # ×”×©×•×•××ª ×¢×œ×•×ª ×××•×¦×¢×ª
        avg_cost_per_workshop = cost_by_garage['mean'].mean()
        expensive_workshops = cost_by_garage[cost_by_garage['mean'] > avg_cost_per_workshop * 1.3]

        if len(expensive_workshops) > 0:
            alert_level = "warning"
            insights.append(
                f"âš ï¸ **××•×¡×›×™× ×™×§×¨×™× ××”×××•×¦×¢ ×‘-30%+:** {', '.join(expensive_workshops['workshop'].tolist())}"
            )

        # ×”××œ×¦×”
        price_diff_percent = ((most_expensive['mean'] - cheapest['mean']) / cheapest['mean']) * 100
        if price_diff_percent > 50:
            alert_level = "warning"
            insights.append(
                f"ğŸ’¡ **×”××œ×¦×”:** ×©×§×•×œ ×œ×”×¢×‘×™×¨ ×˜×™×¤×•×œ×™× ×-{most_expensive['workshop']} "
                f"×œ-{cheapest['workshop']} - ×—×™×¡×›×•×Ÿ ×¤×•×˜× ×¦×™××œ×™ ×©×œ {price_diff_percent:.0f}% ×‘×¢×œ×•×ª ×××•×¦×¢×ª"
            )
        else:
            insights.append(
                f"âœ… **×”××¡×§× ×”:** ×”×¤×¢×¨ ×‘×™×Ÿ ×”××•×¡×›×™× ×¡×‘×™×¨ ({price_diff_percent:.0f}%)"
            )

        return {
            "insights": insights,
            "alert_level": alert_level,
            "stats": {
                "most_expensive": most_expensive['workshop'],
                "cheapest": cheapest['workshop'],
                "price_diff_percent": price_diff_percent
            }
        }

    def analyze_cost_trends(self, df):
        """
        × ×™×ª×•×— ××’××•×ª ×¢×œ×•×™×•×ª ×œ××•×¨×š ×–××Ÿ

        Args:
            df: DataFrame ×¢× ×¢××•×“×•×ª date, total

        Returns:
            dict: ×ª×•×‘× ×•×ª ×¢×œ ××’××•×ª ×•×©×™× ×•×™×™×
        """
        if df.empty or 'date' not in df.columns or 'total' not in df.columns:
            return {"insights": [], "alert_level": "info"}

        insights = []
        alert_level = "success"

        # ×”××¨×ª ×ª××¨×™×š
        df = df.copy()
        df['date'] = pd.to_datetime(df['date'])
        monthly_costs = df.set_index('date').resample('ME')['total'].sum().reset_index()

        if len(monthly_costs) < 2:
            return {
                "insights": ["ğŸ“Š ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™× ×œ× ×™×ª×•×— ××’××•×ª (× ×“×¨×©×™× ×œ×¤×—×•×ª 2 ×—×•×“×©×™×)"],
                "alert_level": "info"
            }

        # ×—×™×©×•×‘ ××’××”
        recent_3_months = monthly_costs.tail(3)['total'].mean() if len(monthly_costs) >= 3 else monthly_costs['total'].mean()
        prev_3_months = monthly_costs.head(len(monthly_costs)-3).tail(3)['total'].mean() if len(monthly_costs) >= 6 else monthly_costs.head(3)['total'].mean()

        trend_change = ((recent_3_months - prev_3_months) / prev_3_months) * 100 if prev_3_months > 0 else 0

        # ×–×™×”×•×™ ××’××”
        if abs(trend_change) < 10:
            insights.append(f"ğŸ“Š **××’××” ×™×¦×™×‘×”:** ×”×¢×œ×•×™×•×ª × ×©××¨×•×ª ×™×¦×™×‘×•×ª (×©×™× ×•×™ ×©×œ {trend_change:+.1f}%)")
            alert_level = "success"
        elif trend_change > 10:
            insights.append(f"ğŸ“ˆ **×¢×œ×™×™×” ×‘×¢×œ×•×™×•×ª:** ×’×™×“×•×œ ×©×œ {trend_change:.1f}% ×‘-3 ×”×—×•×“×©×™× ×”××—×¨×•× ×™×")
            alert_level = "warning"

            # ×‘×“×™×§×ª ×¡×™×‘×•×ª ××¤×©×¨×™×•×ª
            if len(monthly_costs) >= 3:
                last_month_increase = ((monthly_costs.iloc[-1]['total'] - monthly_costs.iloc[-2]['total']) / monthly_costs.iloc[-2]['total']) * 100
                if last_month_increase > 30:
                    insights.append(f"âš ï¸ **×©×™× ×œ×‘:** ×§×¤×™×¦×” ×—×“×” ×‘×—×•×“×© ×”××—×¨×•×Ÿ ({last_month_increase:.0f}%)")
        else:
            insights.append(f"ğŸ“‰ **×™×¨×™×“×” ×‘×¢×œ×•×™×•×ª:** ×—×™×¡×›×•×Ÿ ×©×œ {abs(trend_change):.1f}% ×‘-3 ×”×—×•×“×©×™× ×”××—×¨×•× ×™×")
            alert_level = "success"
            insights.append("âœ… **××¢×•×œ×”!** ×”××’××” ×—×™×•×‘×™×ª")

        # ×–×™×”×•×™ ×—×•×“×©×™× ×—×¨×™×’×™×
        monthly_costs['z_score'] = (monthly_costs['total'] - monthly_costs['total'].mean()) / monthly_costs['total'].std()
        outliers = monthly_costs[abs(monthly_costs['z_score']) > 2]

        if len(outliers) > 0:
            for _, outlier in outliers.iterrows():
                month_name = outlier['date'].strftime('%Y-%m')
                insights.append(
                    f"ğŸ” **×—×•×“×© ×—×¨×™×’:** {month_name} - ×¢×œ×•×ª ×©×œ â‚ª{outlier['total']:,.0f} "
                    f"(×¡×˜×™×™×ª ×ª×§×Ÿ: {outlier['z_score']:.1f})"
                )

        return {
            "insights": insights,
            "alert_level": alert_level,
            "stats": {
                "trend_change_percent": trend_change,
                "recent_avg": recent_3_months,
                "outliers_count": len(outliers)
            }
        }

    def analyze_vehicle_model_costs(self, df):
        """
        × ×™×ª×•×— ×¢×œ×•×™×•×ª ×œ×¤×™ ×“×’× ×¨×›×‘

        Args:
            df: DataFrame ×¢× ×¢××•×“×•×ª make_model, total

        Returns:
            dict: ×ª×•×‘× ×•×ª ×¢×œ ×“×’××™× ×™×§×¨×™×/×–×•×œ×™×
        """
        if df.empty or 'make_model' not in df.columns or 'total' not in df.columns:
            return {"insights": [], "alert_level": "info"}

        insights = []
        alert_level = "success"

        # × ×™×ª×•×— ×œ×¤×™ ×“×’×
        model_analysis = df.groupby('make_model').agg({
            'total': ['sum', 'mean', 'count']
        }).reset_index()
        model_analysis.columns = ['make_model', 'total_cost', 'avg_cost', 'service_count']
        model_analysis = model_analysis.sort_values('total_cost', ascending=False)

        # ×“×’× ×”×›×™ ×™×§×¨
        most_expensive = model_analysis.iloc[0]
        insights.append(
            f"ğŸš— **×”×“×’× ×”×™×§×¨ ×‘×™×•×ª×¨:** {most_expensive['make_model']} - "
            f"â‚ª{most_expensive['total_cost']:,.0f} ×¡×”\"×› "
            f"({most_expensive['service_count']:.0f} ×˜×™×¤×•×œ×™×)"
        )

        # ×“×’× ×”×›×œ×›×œ×™
        cheapest = model_analysis.iloc[-1]
        insights.append(
            f"ğŸ’š **×”×“×’× ×”×›×œ×›×œ×™ ×‘×™×•×ª×¨:** {cheapest['make_model']} - "
            f"â‚ª{cheapest['total_cost']:,.0f} ×¡×”\"×›"
        )

        # ×¢×œ×•×ª ×××•×¦×¢×ª ×œ×˜×™×¤×•×œ
        overall_avg = model_analysis['avg_cost'].mean()
        expensive_models = model_analysis[model_analysis['avg_cost'] > overall_avg * 1.5]

        if len(expensive_models) > 0:
            alert_level = "warning"
            insights.append(
                f"âš ï¸ **×“×’××™× ×¢× ×¢×œ×•×ª ×˜×™×¤×•×œ ×’×‘×•×”×” (50%+ ××”×××•×¦×¢):** "
                f"{', '.join(expensive_models['make_model'].tolist())}"
            )
            insights.append(
                f"ğŸ’¡ **×”××œ×¦×”:** ×©×§×•×œ ×œ×”×—×œ×™×£ ×“×’××™× ××œ×• ×‘×’×¨×™×˜×” ×”×‘××” ×‘×“×’××™× ×›×œ×›×œ×™×™× ×™×•×ª×¨"
            )

        # ×—×œ×•×§×” ×‘××—×•×–×™×
        model_analysis['percentage'] = (model_analysis['total_cost'] / model_analysis['total_cost'].sum()) * 100
        top_contributor = model_analysis.iloc[0]

        if top_contributor['percentage'] > 40:
            insights.append(
                f"ğŸ“Š **×¨×™×›×•×– ×¢×œ×•×™×•×ª:** {top_contributor['make_model']} ××—×¨××™ ×œ-{top_contributor['percentage']:.0f}% ××¡×š ×”×”×•×¦××•×ª"
            )

        return {
            "insights": insights,
            "alert_level": alert_level,
            "stats": {
                "most_expensive_model": most_expensive['make_model'],
                "cheapest_model": cheapest['make_model'],
                "top_percentage": top_contributor['percentage']
            }
        }

    def analyze_scatter_outliers(self, df):
        """
        × ×™×ª×•×— ×—×¨×™×’×•×ª ×‘×’×¨×£ ×”×¤×™×–×•×¨ (×§×™×œ×•××˜×¨××–' vs ×¢×œ×•×ª)

        Args:
            df: DataFrame ×¢× ×¢××•×“×•×ª odometer_km, total, kind (optional)

        Returns:
            dict: ×ª×•×‘× ×•×ª ×¢×œ ×—×¨×™×’×•×ª ×•×“×¤×•×¡×™×
        """
        if df.empty or 'odometer_km' not in df.columns or 'total' not in df.columns:
            return {"insights": [], "alert_level": "info"}

        insights = []
        alert_level = "success"

        # ×–×™×”×•×™ ×—×¨×™×’×•×ª ×¡×˜×˜×™×¡×˜×™×•×ª
        df = df.copy()

        # ×—×™×©×•×‘ Z-score ×œ×¢×œ×•×™×•×ª
        df['cost_z_score'] = (df['total'] - df['total'].mean()) / df['total'].std()

        # ×–×™×”×•×™ ×—×¨×™×’×•×ª ×—××•×¨×•×ª (Z > 3)
        severe_outliers = df[abs(df['cost_z_score']) > 3]

        if len(severe_outliers) > 0:
            alert_level = "warning"
            insights.append(
                f"âš ï¸ **×–×•×”×• {len(severe_outliers)} ×—×¨×™×’×•×ª ×—××•×¨×•×ª** - ×˜×™×¤×•×œ×™× ×¢× ×¢×œ×•×ª ×’×‘×•×”×” ×‘×¦×•×¨×” ×—×¨×™×’×”"
            )

            # ×¤×™×¨×•×˜ ×”×—×¨×™×’×•×ª ×”×§×™×¦×•× ×™×•×ª
            top_outliers = severe_outliers.nlargest(3, 'total')
            for idx, row in top_outliers.iterrows():
                km = row['odometer_km']
                cost = row['total']
                kind = row.get('kind', '×œ× ×™×“×•×¢')
                plate = row.get('plate', '×œ× ×™×“×•×¢')

                insights.append(
                    f"  ğŸ”´ {plate}: â‚ª{cost:,.0f} ×‘-{km:,.0f} ×§\"× ({kind})"
                )

        # × ×™×ª×•×— ×œ×¤×™ ×¡×•×’ ×˜×™×¤×•×œ
        if 'kind' in df.columns:
            kind_analysis = df.groupby('kind').agg({
                'total': ['mean', 'count']
            }).reset_index()
            kind_analysis.columns = ['kind', 'avg_cost', 'count']
            kind_analysis = kind_analysis.sort_values('avg_cost', ascending=False)

            most_expensive_kind = kind_analysis.iloc[0]
            insights.append(
                f"ğŸ’° **×¡×•×’ ×”×˜×™×¤×•×œ ×”×™×§×¨ ×‘×™×•×ª×¨:** {most_expensive_kind['kind']} "
                f"(×××•×¦×¢ â‚ª{most_expensive_kind['avg_cost']:,.0f})"
            )

        # × ×™×ª×•×— ×§×•×¨×œ×¦×™×”
        correlation = df['odometer_km'].corr(df['total'])

        if abs(correlation) < 0.3:
            insights.append(
                "ğŸ“Š **××™×Ÿ ×§×©×¨ ×—×–×§** ×‘×™×Ÿ ×§×™×œ×•××˜×¨××–' ×œ×¢×œ×•×ª ×˜×™×¤×•×œ - ×”×¢×œ×•×™×•×ª ××•×©×¤×¢×•×ª ××’×•×¨××™× ××—×¨×™×"
            )
        elif correlation > 0.5:
            insights.append(
                f"ğŸ“ˆ **×§×©×¨ ×—×™×•×‘×™ ×—×–×§** ({correlation:.2f}) - ×›×›×œ ×©×”×¨×›×‘ ××–×“×§×Ÿ, ×”×¢×œ×•×™×•×ª ×¢×•×œ×•×ª"
            )
            alert_level = "info"

        # ×–×™×”×•×™ ×“×¤×•×¡ ×©×œ ×§×‘×•×¦×•×ª
        low_km_high_cost = df[(df['odometer_km'] < df['odometer_km'].quantile(0.25)) &
                              (df['total'] > df['total'].quantile(0.75))]

        if len(low_km_high_cost) > 5:
            insights.append(
                f"ğŸ” **×“×¤×•×¡ ××¢× ×™×™×Ÿ:** {len(low_km_high_cost)} ×˜×™×¤×•×œ×™× ×™×§×¨×™× ×‘×¨×›×‘×™× ×¢× ×§×™×œ×•××˜×¨××–' × ××•×š - "
                "×™×™×ª×›×Ÿ ×©××“×•×‘×¨ ×‘×ª××•× ×•×ª ××• ×ª×§×œ×•×ª ××™×•×—×“×•×ª"
            )

        # ×¡×™×›×•× ×›×œ×œ×™
        if alert_level == "success":
            insights.insert(0, "âœ… **××¦×‘ ×ª×§×™×Ÿ:** ×”×¢×œ×•×™×•×ª × ××¦××•×ª ×‘×˜×•×•×— ×¡×‘×™×¨ ×œ×œ× ×—×¨×™×’×•×ª ××©××¢×•×ª×™×•×ª")

        return {
            "insights": insights,
            "alert_level": alert_level,
            "stats": {
                "severe_outliers": len(severe_outliers),
                "correlation": correlation
            }
        }


def render_insights_box(insights_data):
    """
    ××¦×™×’ ××ª ×”×ª×•×‘× ×•×ª ×‘×××©×§ Streamlit

    Args:
        insights_data: dict ×¢× insights, alert_level
    """
    import streamlit as st

    if not insights_data or not insights_data.get("insights"):
        return

    alert_level = insights_data.get("alert_level", "info")
    insights = insights_data.get("insights", [])

    # ×‘×—×™×¨×ª ×¦×‘×¢ ×œ×¤×™ ×¨××ª ×”×ª×¨××”
    if alert_level == "warning":
        st.warning("ğŸ“Š **×ª×•×‘× ×•×ª AI ××”×’×¨×£:**")
    elif alert_level == "success":
        st.success("ğŸ“Š **×ª×•×‘× ×•×ª AI ××”×’×¨×£:**")
    else:
        st.info("ğŸ“Š **×ª×•×‘× ×•×ª AI ××”×’×¨×£:**")

    # ×”×¦×’×ª ×›×œ ×”×ª×•×‘× ×•×ª
    for insight in insights:
        st.markdown(f"- {insight}")
